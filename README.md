This repository contains a single Colab notebook that takes you end to end through building a transformer-based Large Language Model from scratch. It implements the core Transformer blocks, shows how to download and load pretrained weights, details a pipeline for converting PDF books into clean TXT training data, demonstrates generating question–answer pairs so the model can learn to answer questions, and finishes with practical evaluation—both quantitative metrics and qualitative prompts. Use it as a self-contained, hands-on lab for understanding, training, and assessing modern LLMs.
